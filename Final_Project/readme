Youtube link
https://youtu.be/Vpvy4SLxQ9Q

## Machine Learning for Medical Diagnosis

Best accuracy we are getting is with Apache MXNET of 88.5 % and high level SDK Image Classification Algorithm gives 88.4 % accuracy in with hyperparameters. Tensorflow is not performing too weel with accuracy of 44 % and low level SDK image classification algorithm with
accuracy of 84 % which is also great.

In this project, We are going to create a REST API for doing breast cancer detection from histopathology images which is publically available imageset on kaggle, which later can be integrated into a full web application that doctors can use for doing diagnostics..
We would be using image classification algorithms in AWS sagemaker that integrate seamlessly with the REST API. 
Now, I'll introduce you to the AWS SageMaker fundamental concepts so you have a better understanding of the platform before 
I tell you how to build a REST API for breast cancer detection. So, what is AWS SageMaker? 
It is a fully managed machine learning service. With SageMaker, everyday data scientists and developers, just like us, 
can quickly and easily build, train, and deploy machine learning models into production‑ready hosted environments. 
For building, AWS SageMaker provides notebook instances which come with Jupyter preinstalled, so you can start 
creating your notebooks right away. It also comes with pre‑built notebooks, which contain several examples that 
can help you with your initial steps in the platform. SageMaker also comes with built‑in, high‑performance algorithms 
that have been optimized for faster running speeds, and you can use them from the very first moment. 
Also, if you prefer, you can create your own algorithms. So, what's the difference between using built‑in algorithms 
and using your own algorithms? Well, using built‑in algorithms has many advantages. You have several algorithms 
that you can use for a variety of problem types. They are ready to be used and optimized for production workloads 
however, using your own algorithms gives you the flexibility to use almost any algorithm code in implementation language
in any dependent libraries and frameworks. And one important thing to mention is that you can use TensorFlow and 
Apache MXNet Docker containers that are already provided by AWS SageMaker. One important thing to take into account is 
that AWS SageMaker offers several built‑in algorithms, and the problem you want to solve influences the algorithm you choose. 
We want  to classify images into categories, as we're going to do for our Breast Cancer Detection API, you can use the 
Image Classification algorithm.

For training, AWS SageMaker helps you with the hyperparameter optimization process. 
You don't have to waste your time anymore by doing random trial and error tuning. 
AWS SageMaker takes care of hyperparameter optimization for you. For deploying, AWS SageMaker 
helps you with the provision of endpoints so external applications can easily get predictions 
from your trained model. AWS SageMaker provides notebook instances where you can start building 
your machine learning models. A notebook instance, put in simple words, is a fully managed 
machine learning compute instance running the Jupyter Notebook app, including related resources. 
So, what are those related resources I'm talking about? They include Anaconda packages for data science, 
TensorFlow and Apache MXNet, storage volume, which you can use to locally process a large dataset or to 
temporarily store other data to work with, example Jupyter Notebooks that contain several use cases you can 
take a look at to get started with the AWS SageMaker platform. And, if you're wondering about what tasks you
can perform on a notebook instance, you can prepare and process input data for your models, write code to 
train models, deploy models to AWS SageMaker hosting, and test or validate your models.

Let's take a look now to Building a Model in AWS SageMaker for Breast Cancer Detection Using a Built‑in Algorithm.
For this case, the most appropriate built‑in algorithm to use will be the image classification algorithm. 
It is a supervised learning algorithm which takes an image as an input and classifies it into one of multiple 
categories using a convolutional neural network. 

One important thing to notice is that you can configure the training mode for this algorithm, which falls into two categories, 
full training and transfer learning. In full training mode, the neural network is initialized with random weights and trained 
from scratch, so it needs a lot of input images. In transfer learning mode, the neural network is initialized with pre‑trained weights, 
and just the top fully connected layer is initialized with random weights, so it needs a smaller number of input images. 
When training, the whole network is fine‑tuned with user images. 

Another important aspect of the image classification algorithm is that it accepts two formats for input images. 
The first one, and also the recommended one, is the Apache MXNet RecordIO format. The second one is raw images in JPEG or PNG format. 

So, what's the difference between using RecordIO and raw images? If you use RecordIO, you can take advantage of AWS SageMaker Pipe mode.
In Pipe mode, your training job streams data directly from S3, which means faster start times, better throughput, and reduced storage 
volume usage. On the other side, using raw images means AWS SageMaker will use File mode by default. In file mode, your training job 
loads all your training data from S3 to the training instance volumes first, which means slower start times, lower throughput, and 
higher storage volume usage. Loading raw images can work on Pipe mode too; however, you have to provide an additional augmented manifest
file. 

Moving on the with image classification algorithm configuration, it has several hyperparameters that can be adjusted for a 
better performance, which, at the end of the day, means having a more accurate model for doing breast cancer detection and saving
more lives. 

The definition of hyperparameter, it is a parameter that set before the learning process begins. These parameters are tunable, and 
can directly affect how well a model trains. 
The image classification algorithm has two required hyperparameters. One is the number of classes, which for the breast cancer 
detection problem we want to solve will just be two, meaning cancer detected or no cancer detected. The other one is the number 
of training samples or the number of images we are going to use for training the model. 
SageMaker has two available APIs for building models using built‑in algorithms. The first one is a low‑level AWS SDK for Python, 
and the second one is a high‑level SageMaker Python library.

The first step will be creating a new Jupyter notebook. Next, we have built the process for obtaining the histopathology images that 
will be used as input for the image classification algorithm. Then, we are going to explore the images so we have a sense of what it 
is we are dealing with. And finally, we are going to convert the images to the RecordIO format because that is the most performant 
solution and then upload to s3.  

Now we will be building a model in AWS SageMaker for breast cancer detection using Tensorflow. This means creating a custom algorithm
of our own instead of using the built‑in image classification algorithm. By the way, the latest version of Tensorflow supported by the 
SageMaker Python SDK is 1.12.0. Please remember, it's recommended to use the latest supported version of Tensorflow, because that's 
where AWS focuses most of its development efforts. 

The process we're going to follow for building a Tensorflow model in SageMaker is the following. First, we're going to transform the 
input images to the TFRecord format, which, like the RecordIO format we have discussed before, is more efficient for training. 
Then we're going to prepare a training  script. And finally, we're going to build a model using the Tensorflow estimator provided 
by the SageMaker Python SDK. 

SageMaker gives your script access to useful properties about the training environment through environment variables. Some of the 
available environment variables are SM_MODEL_DIR, which is a string that represents the local path where the training job can write
the model artifact to. After training, artifacts in this directory are uploaded to S3 for model hosting. SM_NUM_GPUS, this is an 
integer representing the the number of GPUs available to the host. SM_OUTPUT_DATA_DIR, this is a string that represents the path 
to the directory to write output artifacts to. Output artifacts might include checkpoints, graphs, and other files to save, 
but do not include model artifacts. These artifacts are compressed and uploaded to an S3 bucket with the same prefix as the model
artifact. SM_CHANNEL, it is a string that represents the path to the directory that contains the input data for the specified channel.
For example, if you specify two input channels in a Tensorflow estimator's feed call named train and test, the environment variables
SM_CHANNEL_TRAIN and SM_CHANNEL_TEST are set.


Lets see how to build a model using Apache MXNet. The latest version of Apache MXNet supported by the SageMaker Python SDK is 1.3.0.
And, as I've mentioned before for TensorFlow, please remember it's recommended to use the latest supported version of MXNet because 
that's where AWS focuses most of its development efforts. 

The process we're going to follow for building an MXNet model in SageMaker is very similar to the process we have used for TensorFlow. 
First, we're going to transfer the input images to the RecordIO format we have discussed before because it's more efficient for training.
Then, we're going to prepare a training script. And finally, we're going to build a model using the MXNet Estimator provided by the
SageMaker Python SDK. 

SageMaker gives your MXNet script access to useful properties about the training environment through environment variables. 
Just to remember, these are some of the available environment variables, and they are basically the same as in the TensorFlow case, 
SM_MODEL_DIR, SM_NUM_GPUS, SM_OUTPUT_DATA_DIR, and SM_CHANNEL.


Let's move on now and talk about automatic hyperparameter optimization, HPO, in SageMaker. A problem we all have to face when 
building and training machine learning models is that selecting the right hyperparameter values can be difficult. The right answer 
depends on the algorithm and the data. 

Automatic hyperparameter optimization help us find the best version of a model by running many training jobs. For that, it uses 
the algorithm and ranges of hyperparameters that you specify, and it chooses the hyperparameter values that result in a model that
performs the best as measured by a metric that you choose. At the end of the day, hyperparameter optimization is a supervised learning
problem. Given a set of input features, the hyperparameters, hyperparameter tuning optimizes a model for the metric that you choose. 

We can define objective metrics for hyperparameter optimization. When using built‑in algorithms, you don't need to define metrics. 
They are sent automatically to hyperparameter tuning; however, you do need to choose the objective metric for the tuning job. 
When using custom algorithms, your algorithm has to emit at least one metric by writing evaluation data to stderr or stdout. 
You can define up to 20 metrics for the tuning job to monitor. You choose one of those metrics to be the objective metric. 
You define metrics by specifying a name and a regular expression for parsing training logs. By the way, the built‑in image 
classification algorithm has many tunable hyperparameters, the mini_batch_size, the learning_rate, the optimizer, and other 
hyperparameters related with the optimizer itself, beta_1, beta_2, eps, gamma, momentum, and weight_decay.


Let's see now how we can deploy and test machine learning models in AWS SageMaker hosting services. Deploying a model using AWS 
SageMaker hosting service is a three‑step process. First, you have to create a model in AWS SageMaker. By creating a model, you tell
SageMaker where it can find the model component, which include the S3 path where the model artifacts are stored. The model artifacts
are the outputs we get when training a model. And also, the Docker registry path for the image that will be used for making predictions.
Then you have to create an endpoint configuration for an HTTPS endpoint. Here is where you specify the name of the model you want to 
deploy and the number and type of machine learning compute instances that you want a AWS SageMaker to launch to host them all. Finally,
you have to create an HTTPS endpoint. For that, you provide an endpoint configuration that was previously created. So, AWS SageMaker
launches the machine learning computer instances and deploys the model as specified in the configuration. Something important to notice 
here is that if you specify you want two or more instances for deploying a model, AWS SageMaker launches them in multiple Availability 
Zones, ensuring high availability. 

After a model is deployed in AWS SageMaker, to validate it, you can send sample requests and get inferences directly from a Jupyter 
Notebook.

So, the REST API for breast cancer detection is already deployed in AWS SageMaker, and they'll just call it from Postman. By the way, I'm using Postman's 7.0.9 on a windows machine have a preconfigured request for calling the REST API. When the request gets executed, this image will be sent to the REST API. It is a histopathology image of a patient who doesn't have breast cancer. It is a very small image with a resolution of 50 x 50 pixels. And, if you're wondering about where I have obtained this image, don't worry, I'll let you know when we start building our models in SageMaker. So, I'll just send the request now. I'm getting a response that says the image we have just sent doesn't correspond to a breast cancer case, as we expected. So the API is working okay. 

